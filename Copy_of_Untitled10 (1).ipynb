{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YIhSR3_bsQNK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from numpy import random\n",
        "#import tensorflow_datasets as tfds\n",
        "#import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,LayerNormalization,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input,MultiHeadAttention,Embedding,TextVectorization)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
        "#from google.colab import drive\n",
        "#from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "izJDhdfj5giP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the Excel sheet into a DataFrame\n",
        "excel_file_path = r'C:\\saipragatheeswar\\thesis phase2\\transformer\\final dataset ai - human.xlsx'  # Replace with the path to your Excel file\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "def process_data(row):\n",
        "    # Concatenate 'starttoken ' with the 'humanembedding' column and ' endtoken' to the 'AIembedding' column\n",
        "    input_1 = row['Human']\n",
        "    input_2 = 'starttoken ' + row['AI'] + ' endtoken'\n",
        "\n",
        "    # Create tensors with the specified format\n",
        "    tensor_1 = tf.constant([input_1], dtype=tf.string)\n",
        "    tensor_2 = tf.constant([input_2], dtype=tf.string)\n",
        "\n",
        "    return (tensor_1, tensor_2)\n",
        "\n",
        "# Apply the process_data function to each row in the DataFrame and store the results in a list\n",
        "data = [process_data(row) for _, row in df.iterrows()]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T4fpn4NhNwPE"
      },
      "outputs": [],
      "source": [
        "def data_generator():\n",
        "    for item in data:\n",
        "        yield item\n",
        "\n",
        "# Create a dataset from the generator\n",
        "dataset = tf.data.Dataset.from_generator(data_generator, output_signature=(\n",
        "    tf.TensorSpec(shape=(1,), dtype=tf.string),\n",
        "    tf.TensorSpec(shape=(1,), dtype=tf.string)\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkvyzN5RKUl8"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJpgmtJTMUCR",
        "outputId": "5ba995a2-8fe4-4821-a6d0-831cffb2a88e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"I can't find my Glasses, can you help me?\"], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
            "array([b'starttoken Give me a moment to locate your thing. endtoken'],\n",
            "      dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"I've lost my Belt, can you assist me?\"], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
            "array([b\"starttoken I'm searching for your object right now. endtoken\"],\n",
            "      dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"I can't find my Necklace, can you help me?\"], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
            "array([b\"starttoken Sure, I'll help you find your object. endtoken\"],\n",
            "      dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for element in dataset.take(3):\n",
        "    print(element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9GOXXqtQGpgt"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE=2000\n",
        "ENGLISH_SEQUENCE_LENGTH=32\n",
        "FRENCH_SEQUENCE_LENGTH=32\n",
        "EMBEDDING_DIM=256\n",
        "BATCH_SIZE=128\n",
        "\n",
        "english_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")\n",
        "english_vectorize_layer1=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8H7g-6vbGebH"
      },
      "outputs": [],
      "source": [
        "english_training_data = dataset.map(lambda x,y:x)\n",
        "english_vectorize_layer.adapt(english_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SRZp768OGf3G"
      },
      "outputs": [],
      "source": [
        "english_training_data1=dataset.map(lambda x,y:y)\n",
        "english_vectorize_layer1.adapt(english_training_data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxEmEVBjehYp",
        "outputId": "d8ea428d-b833-4339-ce42-df5c4ca36c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"I can't find my Glasses, can you help me?\"], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Give me a moment to locate your thing.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Give me a moment to locate your thing. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"I've lost my Belt, can you assist me?\"], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
            "array([b\"starttoken I'm searching for your object right now.\"],\n",
            "      dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"I'm searching for your object right now. endtoken\"], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"I can't find my Necklace, can you help me?\"], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"starttoken Sure, I'll help you find your object.\"], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"Sure, I'll help you find your object. endtoken\"], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming you already have your 'data' list defined as shown in the previous example\n",
        "def process_data(row):\n",
        "    # Concatenate 'starttoken ' with the 'humanembedding' column and ' endtoken' to the 'AIembedding' column\n",
        "    input_1 = row['Human']\n",
        "    input_2 = 'starttoken ' + row['AI']\n",
        "    target = row['AI'] +' '+ 'endtoken'  # This will be the expected output\n",
        "\n",
        "    return {'input_1': tf.constant([input_1]), 'input_2': tf.constant([input_2])}, tf.constant([target])\n",
        "\n",
        "# Apply the process_data function to each row in the DataFrame and store the results in a list\n",
        "data1 = [process_data(row) for _, row in df.iterrows()]\n",
        "# Convert the list of data into a TensorFlow Dataset\n",
        "dataset2 = tf.data.Dataset.from_generator(\n",
        "    lambda: (item for item in data1),\n",
        "    output_signature=(\n",
        "        {\n",
        "            'input_1': tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
        "            'input_2': tf.TensorSpec(shape=(None,), dtype=tf.string)\n",
        "        },\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.string)\n",
        "    )\n",
        ")\n",
        "for i in dataset2.take(3):\n",
        "  print(i)\n",
        "# Define your vectorizer function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TRKfO3U1r-n",
        "outputId": "ada7f5e9-2ae9-4940-cf90-10da0aacaf72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "endtoken\n"
          ]
        }
      ],
      "source": [
        "for i in english_vectorize_layer1.get_vocabulary():\n",
        "  if i == 'endtoken':\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z8ct4Pup704I"
      },
      "outputs": [],
      "source": [
        "def vectorizer(inputs, output):\n",
        "    return {\n",
        "        'input_1': english_vectorize_layer(inputs['input_1']),\n",
        "        'input_2': english_vectorize_layer1(inputs['input_2'])\n",
        "    }, english_vectorize_layer1(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zhGGZADb_-KT"
      },
      "outputs": [],
      "source": [
        "dataset11=dataset2.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAYW7_CM77A9",
        "outputId": "3fa44400-bfd9-44ab-a1fc-f0e170a1f4d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 8, 16, 15,  2, 60,  4,  3, 14,  5,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 2, 26, 24, 12, 22,  7, 25,  4, 23,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[26, 24, 12, 22,  7, 25,  4, 23,  3,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[18, 17,  2, 27,  4,  3, 12,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 2, 10, 29, 15,  4,  5, 17, 28,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[10, 29, 15,  4,  5, 17, 28,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 8, 16, 15,  2, 77,  4,  3, 14,  5,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 2, 30,  6, 18,  8,  9,  4,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[30,  6, 18,  8,  9,  4,  5,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset11.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB33E4ePxu0p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FFukpxBnzIjy"
      },
      "outputs": [],
      "source": [
        "NUM_BATCHES=int(200000/BATCH_SIZE)\n",
        "train_dataset=dataset11.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset11.skip(int(0.9*NUM_BATCHES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZtaQ1GjvOOD",
        "outputId": "09226ff9-d9c7-45b3-a91c-78ee6bc21644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 8, 16, 15,  2, 60,  4,  3, 14,  5,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 2, 26, 24, 12, 22,  7, 25,  4, 23,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[26, 24, 12, 22,  7, 25,  4, 23,  3,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[18, 17,  2, 27,  4,  3, 12,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 2, 10, 29, 15,  4,  5, 17, 28,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[10, 29, 15,  4,  5, 17, 28,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 8, 16, 15,  2, 77,  4,  3, 14,  5,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 2, 30,  6, 18,  8,  9,  4,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[30,  6, 18,  8,  9,  4,  5,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 8, 16, 15,  2, 29, 43,  4,  3, 14,  5,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 2,  6, 16, 21, 27,  7,  9,  4,  5,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 6, 16, 21, 27,  7,  9,  4,  5,  3,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[13,  3, 11,  7,  2, 60,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[ 2, 10, 29, 15,  4,  5, 17, 28,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[10, 29, 15,  4,  5, 17, 28,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
            "      dtype=int64)>)\n"
          ]
        }
      ],
      "source": [
        "for i in train_dataset.take(5):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SZuB1T2VoAkt"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(model_size,SEQUENCE_LENGTH):\n",
        "  output=[]\n",
        "  for pos in range(SEQUENCE_LENGTH):\n",
        "    PE=np.zeros((model_size))\n",
        "    for i in range(model_size):\n",
        "      if i%2==0:\n",
        "        PE[i]=np.sin(pos/(10000**(i/model_size)))\n",
        "      else:\n",
        "        PE[i]=np.cos(pos/(10000**((i-1)/model_size)))\n",
        "    output.append(tf.expand_dims(PE,axis=0))\n",
        "  out=tf.concat(output,axis=0)\n",
        "  out=tf.expand_dims(out,axis=0)\n",
        "  return tf.cast(out,dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NzsHmKaTsMgH"
      },
      "outputs": [],
      "source": [
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocab_size, embed_dim,):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.token_embeddings=Embedding(\n",
        "        input_dim=vocab_size, output_dim=embed_dim)\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions=positional_encoding(\n",
        "        self.embed_dim,self.sequence_length)\n",
        "    return embedded_tokens + embedded_positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    return tf.math.not_equal(inputs, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Fbvj6uCpv2uN"
      },
      "outputs": [],
      "source": [
        "class CustomSelfAttention(Layer):\n",
        "  def __init__(self,model_size):\n",
        "    super(CustomSelfAttention,self).__init__()\n",
        "    self.model_size=model_size\n",
        "  def call(self,query,key,value,masking):\n",
        "    ######## compute scores\n",
        "    score=tf.matmul(query,key,transpose_b=True)\n",
        "    ######## scaling\n",
        "    score/=tf.math.sqrt(tf.cast(self.model_size,tf.float32))\n",
        "    ######## masking\n",
        "    masking=tf.cast(masking,dtype=tf.float32)\n",
        "    score+=(1.-masking)*-1e10\n",
        "    ######## attention_weights\n",
        "    attention=tf.nn.softmax(score,axis=-1)*masking\n",
        "    ######## output\n",
        "    head=tf.matmul(attention,value)\n",
        "    return head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "I2nrur74vv0D"
      },
      "outputs": [],
      "source": [
        "class CustomMultiHeadAttention(Layer):\n",
        "  def __init__(self,num_heads,key_dim):\n",
        "    super(CustomMultiHeadAttention,self).__init__()\n",
        "\n",
        "    self.num_heads=num_heads\n",
        "    self.dense_q=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
        "    self.dense_k=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
        "    self.dense_v=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
        "    self.dense_o=Dense(key_dim)\n",
        "    self.self_attention=CustomSelfAttention(key_dim)\n",
        "\n",
        "  def call(self,query,key,value,attention_mask):\n",
        "    heads=[]\n",
        "\n",
        "    for i in range(self.num_heads):\n",
        "      print(\"hello\", self.dense_q[i](query).shape)\n",
        "      head=self.self_attention(self.dense_q[i](query),self.dense_k[i](key),\n",
        "                              self.dense_v[i](value),attention_mask)\n",
        "      heads.append(head)\n",
        "    heads=tf.concat(heads,axis=2)\n",
        "    heads=self.dense_o(heads)\n",
        "    return heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QASNg9fgtwQl"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads,):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = CustomMultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim,\n",
        "        )\n",
        "        self.dense_proj=tf.keras.Sequential(\n",
        "            [Dense(dense_dim, activation=\"relu\"),\n",
        "             Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = LayerNormalization()\n",
        "        self.layernorm_2 = LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "\n",
        "      if mask is not None:\n",
        "        mask = tf.cast(\n",
        "            mask[:,tf.newaxis, :], dtype=\"int32\")\n",
        "        T = tf.shape(mask)[2]\n",
        "        padding_mask = tf.repeat(mask,T,axis=1)\n",
        "      attention_output = self.attention(\n",
        "          query=inputs, key=inputs,value=inputs,\n",
        "          attention_mask=padding_mask\n",
        "      )\n",
        "\n",
        "      proj_input = self.layernorm_1(inputs + attention_output)\n",
        "      proj_output = self.dense_proj(proj_input)\n",
        "      return self.layernorm_2(proj_input + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0QDfx2N3xVJr"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(Layer):\n",
        "  def __init__(self, embed_dim, latent_dim, num_heads,):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.attention_1=MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.attention_2=MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.dense_proj = tf.keras.Sequential(\n",
        "        [Dense(latent_dim, activation=\"relu\"),Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1=LayerNormalization()\n",
        "    self.layernorm_2=LayerNormalization()\n",
        "    self.layernorm_3=LayerNormalization()\n",
        "    self.supports_masking = True\n",
        "  def call(self, inputs, encoder_outputs, enc_mask, mask=None):\n",
        "\n",
        "\n",
        "    if mask is not None:\n",
        "      causal_mask=tf.linalg.band_part(\n",
        "        tf.ones([tf.shape(inputs)[0],\n",
        "                 tf.shape(inputs)[1],\n",
        "                 tf.shape(inputs)[1]],dtype=tf.int32),-1,0)\n",
        "      mask = tf.cast(\n",
        "          mask[:,tf.newaxis, :], dtype=\"int32\")\n",
        "      enc_mask = tf.cast(\n",
        "          enc_mask[:,tf.newaxis, :], dtype=\"int32\")\n",
        "\n",
        "      T = tf.shape(mask)[2]\n",
        "      padding_mask = tf.repeat(mask,T,axis=1)\n",
        "      cross_attn_mask = tf.repeat(enc_mask,T,axis=1)\n",
        "      combined_mask=tf.minimum(padding_mask,causal_mask)\n",
        "\n",
        "    attention_output_1 = self.attention_1(\n",
        "        query=inputs,key=inputs,value=inputs,\n",
        "        attention_mask=combined_mask,\n",
        "\n",
        "    )\n",
        "\n",
        "    out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "    attention_output_2= self.attention_2(\n",
        "        query=out_1,key=encoder_outputs,value=encoder_outputs,\n",
        "        attention_mask=cross_attn_mask,\n",
        "\n",
        "    )\n",
        "    out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "    proj_output = self.dense_proj(out_2)\n",
        "    return self.layernorm_3(out_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "S7En8RDMxEJ6"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM=512\n",
        "D_FF=2048\n",
        "NUM_HEADS=8\n",
        "NUM_LAYERS=1\n",
        "NUM_EPOCHS=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQcKY_YIxFfL",
        "outputId": "80fcf6fb-a1ce-4dd4-cf47-12df95f0a744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello (None, 32, 64)\n",
            "hello (None, 32, 64)\n",
            "hello (None, 32, 64)\n",
            "hello (None, 32, 64)\n",
            "hello (None, 32, 64)\n",
            "hello (None, 32, 64)\n",
            "hello (None, 32, 64)\n",
            "hello (None, 32, 64)\n",
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embeddings (Embeddings)        (None, 32, 512)      1024000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embeddings_1 (Embeddings)      (None, 32, 512)      1024000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, 32, 512)     3152384     ['embeddings[0][0]']             \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.not_equal (TFOpLambda)  (None, None)        0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " transformer_decoder (Transform  (None, 32, 512)     18905600    ['embeddings_1[0][0]',           \n",
            " erDecoder)                                                       'transformer_encoder[0][0]',    \n",
            "                                                                  'tf.math.not_equal[0][0]']      \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 32, 512)      0           ['transformer_decoder[0][0]']    \n",
            "                                                                                                  \n",
            " dense_29 (Dense)               (None, 32, 2000)     1026000     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,131,984\n",
            "Trainable params: 25,131,984\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n",
        "emb = Embeddings(ENGLISH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)\n",
        "x = emb(encoder_inputs)\n",
        "enc_mask = emb.compute_mask(encoder_inputs)\n",
        "\n",
        "for _ in range(NUM_LAYERS):\n",
        "  x=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n",
        "encoder_outputs=x\n",
        "\n",
        "decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n",
        "\n",
        "x = Embeddings(FRENCH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(decoder_inputs)\n",
        "for i in range(NUM_LAYERS):\n",
        "  x=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs,enc_mask)\n",
        "x=tf.keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")\n",
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IGc2RiMixFbv"
      },
      "outputs": [],
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='bleu_score'):\n",
        "        super(BLEU,self).__init__()\n",
        "        self.bleu_score=0\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred,-1)\n",
        "      self.bleu_score=0\n",
        "      for i,j in zip(y_pred,y_true):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches=0\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if word==j[q]:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "\n",
        "        self.bleu_score+=total_matches/total_words\n",
        "\n",
        "    def result(self):\n",
        "        return self.bleu_score/BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "l26mCaI6xFYq"
      },
      "outputs": [],
      "source": [
        "class Scheduler(LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps):\n",
        "    super(Scheduler, self).__init__()\n",
        "    self.d_model = tf.cast(d_model, tf.float64)\n",
        "    self.warmup_steps = tf.cast(warmup_steps, dtype=tf.float64)\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float64)\n",
        "    return (self.d_model**(-0.5))*tf.math.minimum(step**(-0.5), step * (self.warmup_steps ** -1.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-0eowvAC1P6t"
      },
      "outputs": [],
      "source": [
        "WARM_UP_STEPS = 4000\n",
        "lr_scheduled = Scheduler(EMBEDDING_DIM, WARM_UP_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "X6KWcAyf1PwM"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = Adam(lr_scheduled, beta_1=0.9, beta_2=0.98, epsilon=1e-9),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaPtE7dD1Psq",
        "outputId": "30ae78d0-a7ca-42d3-c229-fbaa4ebdc908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0812 - val_loss: 0.9232\n",
            "Epoch 2/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0721 - val_loss: 1.0153\n",
            "Epoch 3/200\n",
            "1405/1405 [==============================] - 124s 88ms/step - loss: 0.0571 - val_loss: 1.1238\n",
            "Epoch 4/200\n",
            "1405/1405 [==============================] - 117s 83ms/step - loss: 0.0557 - val_loss: 1.2419\n",
            "Epoch 5/200\n",
            "1405/1405 [==============================] - 119s 85ms/step - loss: 0.0542 - val_loss: 1.2225\n",
            "Epoch 6/200\n",
            "1405/1405 [==============================] - 124s 88ms/step - loss: 0.0536 - val_loss: 1.2309\n",
            "Epoch 7/200\n",
            "1405/1405 [==============================] - 120s 86ms/step - loss: 0.0523 - val_loss: 1.2755\n",
            "Epoch 8/200\n",
            "1405/1405 [==============================] - 125s 89ms/step - loss: 0.0530 - val_loss: 1.2669\n",
            "Epoch 9/200\n",
            "1405/1405 [==============================] - 123s 87ms/step - loss: 0.0515 - val_loss: 1.2813\n",
            "Epoch 10/200\n",
            "1405/1405 [==============================] - 121s 86ms/step - loss: 0.0513 - val_loss: 1.2968\n",
            "Epoch 11/200\n",
            "1405/1405 [==============================] - 126s 90ms/step - loss: 0.0521 - val_loss: 1.2455\n",
            "Epoch 12/200\n",
            "1405/1405 [==============================] - 132s 94ms/step - loss: 0.0511 - val_loss: 1.3269\n",
            "Epoch 13/200\n",
            "1405/1405 [==============================] - 127s 90ms/step - loss: 0.0531 - val_loss: 1.2693\n",
            "Epoch 14/200\n",
            "1405/1405 [==============================] - 120s 86ms/step - loss: 0.0511 - val_loss: 1.2489\n",
            "Epoch 15/200\n",
            "1405/1405 [==============================] - 121s 86ms/step - loss: 0.0511 - val_loss: 1.4854\n",
            "Epoch 16/200\n",
            "1405/1405 [==============================] - 126s 90ms/step - loss: 0.0509 - val_loss: 1.4672\n",
            "Epoch 17/200\n",
            "1405/1405 [==============================] - 119s 84ms/step - loss: 0.0510 - val_loss: 1.3608\n",
            "Epoch 18/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0514 - val_loss: 1.3986\n",
            "Epoch 19/200\n",
            "1405/1405 [==============================] - 117s 83ms/step - loss: 0.0510 - val_loss: 1.4593\n",
            "Epoch 20/200\n",
            "1405/1405 [==============================] - 120s 86ms/step - loss: 0.0513 - val_loss: 1.4209\n",
            "Epoch 21/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0509 - val_loss: 1.4291\n",
            "Epoch 22/200\n",
            "1405/1405 [==============================] - 119s 85ms/step - loss: 0.0509 - val_loss: 1.3921\n",
            "Epoch 23/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0510 - val_loss: 1.4360\n",
            "Epoch 24/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0508 - val_loss: 1.5748\n",
            "Epoch 25/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0509 - val_loss: 1.4877\n",
            "Epoch 26/200\n",
            "1405/1405 [==============================] - 130s 93ms/step - loss: 0.0507 - val_loss: 1.4844\n",
            "Epoch 27/200\n",
            "1405/1405 [==============================] - 142s 101ms/step - loss: 0.0507 - val_loss: 1.2298\n",
            "Epoch 28/200\n",
            "1405/1405 [==============================] - 140s 100ms/step - loss: 0.0508 - val_loss: 1.4159\n",
            "Epoch 29/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0507 - val_loss: 1.3396\n",
            "Epoch 30/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0508 - val_loss: 1.2723\n",
            "Epoch 31/200\n",
            "1405/1405 [==============================] - 117s 83ms/step - loss: 0.0509 - val_loss: 1.2135\n",
            "Epoch 32/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0508 - val_loss: 1.3684\n",
            "Epoch 33/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0507 - val_loss: 1.4558\n",
            "Epoch 34/200\n",
            "1405/1405 [==============================] - 120s 85ms/step - loss: 0.0507 - val_loss: 1.5292\n",
            "Epoch 35/200\n",
            "1405/1405 [==============================] - 117s 83ms/step - loss: 0.0507 - val_loss: 1.5577\n",
            "Epoch 36/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0506 - val_loss: 1.4007\n",
            "Epoch 37/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.2105\n",
            "Epoch 38/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0508 - val_loss: 1.4771\n",
            "Epoch 39/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0509 - val_loss: 1.4089\n",
            "Epoch 40/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.4076\n",
            "Epoch 41/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0507 - val_loss: 1.4383\n",
            "Epoch 42/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0507 - val_loss: 1.4898\n",
            "Epoch 43/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0507 - val_loss: 1.3860\n",
            "Epoch 44/200\n",
            "1405/1405 [==============================] - 126s 90ms/step - loss: 0.0507 - val_loss: 1.4651\n",
            "Epoch 45/200\n",
            "1405/1405 [==============================] - 122s 87ms/step - loss: 0.0506 - val_loss: 1.4542\n",
            "Epoch 46/200\n",
            "1405/1405 [==============================] - 123s 87ms/step - loss: 0.0505 - val_loss: 1.4736\n",
            "Epoch 47/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.5518\n",
            "Epoch 48/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0507 - val_loss: 1.4432\n",
            "Epoch 49/200\n",
            "1405/1405 [==============================] - 122s 87ms/step - loss: 0.0506 - val_loss: 1.4668\n",
            "Epoch 50/200\n",
            "1405/1405 [==============================] - 133s 95ms/step - loss: 0.0507 - val_loss: 1.5613\n",
            "Epoch 51/200\n",
            "1405/1405 [==============================] - 122s 87ms/step - loss: 0.0509 - val_loss: 1.5260\n",
            "Epoch 52/200\n",
            "1405/1405 [==============================] - 122s 87ms/step - loss: 0.0507 - val_loss: 1.4865\n",
            "Epoch 53/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0506 - val_loss: 1.4018\n",
            "Epoch 54/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.4449\n",
            "Epoch 55/200\n",
            "1405/1405 [==============================] - 127s 90ms/step - loss: 0.0507 - val_loss: 1.4819\n",
            "Epoch 56/200\n",
            "1405/1405 [==============================] - 120s 86ms/step - loss: 0.0507 - val_loss: 1.2833\n",
            "Epoch 57/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0507 - val_loss: 1.4748\n",
            "Epoch 58/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0508 - val_loss: 1.4363\n",
            "Epoch 59/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.3521\n",
            "Epoch 60/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0507 - val_loss: 1.5009\n",
            "Epoch 61/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.4440\n",
            "Epoch 62/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.3732\n",
            "Epoch 63/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.5067\n",
            "Epoch 64/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0505 - val_loss: 1.4323\n",
            "Epoch 65/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.5759\n",
            "Epoch 66/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0507 - val_loss: 1.6235\n",
            "Epoch 67/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0507 - val_loss: 1.5070\n",
            "Epoch 68/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0505 - val_loss: 1.5113\n",
            "Epoch 69/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0507 - val_loss: 1.4040\n",
            "Epoch 70/200\n",
            "1405/1405 [==============================] - 3929s 3s/step - loss: 0.0506 - val_loss: 1.4638\n",
            "Epoch 71/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.4072\n",
            "Epoch 72/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0505 - val_loss: 1.4936\n",
            "Epoch 73/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.3488\n",
            "Epoch 74/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.4779\n",
            "Epoch 75/200\n",
            "1405/1405 [==============================] - 117s 83ms/step - loss: 0.0506 - val_loss: 1.4517\n",
            "Epoch 76/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0505 - val_loss: 1.4530\n",
            "Epoch 77/200\n",
            "1405/1405 [==============================] - 113s 81ms/step - loss: 0.0506 - val_loss: 1.5386\n",
            "Epoch 78/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.4793\n",
            "Epoch 79/200\n",
            "1405/1405 [==============================] - 113s 81ms/step - loss: 0.0505 - val_loss: 1.5591\n",
            "Epoch 80/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0504 - val_loss: 1.3917\n",
            "Epoch 81/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0504 - val_loss: 1.5462\n",
            "Epoch 82/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0508 - val_loss: 1.5323\n",
            "Epoch 83/200\n",
            "1405/1405 [==============================] - 113s 81ms/step - loss: 0.0506 - val_loss: 1.5610\n",
            "Epoch 84/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0504 - val_loss: 1.4892\n",
            "Epoch 85/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0504 - val_loss: 1.5049\n",
            "Epoch 86/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.4215\n",
            "Epoch 87/200\n",
            "1405/1405 [==============================] - 113s 81ms/step - loss: 0.0506 - val_loss: 1.5337\n",
            "Epoch 88/200\n",
            "1405/1405 [==============================] - 113s 81ms/step - loss: 0.0508 - val_loss: 1.5372\n",
            "Epoch 89/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.5550\n",
            "Epoch 90/200\n",
            "1405/1405 [==============================] - 113s 81ms/step - loss: 0.0506 - val_loss: 1.6048\n",
            "Epoch 91/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0504 - val_loss: 1.5463\n",
            "Epoch 92/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0505 - val_loss: 1.3137\n",
            "Epoch 93/200\n",
            "1405/1405 [==============================] - 113s 81ms/step - loss: 0.0506 - val_loss: 1.4029\n",
            "Epoch 94/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0505 - val_loss: 1.3877\n",
            "Epoch 95/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0505 - val_loss: 1.3005\n",
            "Epoch 96/200\n",
            "1405/1405 [==============================] - 113s 81ms/step - loss: 0.0505 - val_loss: 1.3641\n",
            "Epoch 97/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.2886\n",
            "Epoch 98/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.4040\n",
            "Epoch 99/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0507 - val_loss: 1.4720\n",
            "Epoch 100/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0504 - val_loss: 1.3095\n",
            "Epoch 101/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.2782\n",
            "Epoch 102/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0505 - val_loss: 1.2800\n",
            "Epoch 103/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0506 - val_loss: 1.2129\n",
            "Epoch 104/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0505 - val_loss: 1.1715\n",
            "Epoch 105/200\n",
            "1405/1405 [==============================] - 121s 86ms/step - loss: 0.0504 - val_loss: 1.2812\n",
            "Epoch 106/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0506 - val_loss: 1.3498\n",
            "Epoch 107/200\n",
            "1405/1405 [==============================] - 114s 82ms/step - loss: 0.0506 - val_loss: 1.0755\n",
            "Epoch 108/200\n",
            "1405/1405 [==============================] - 123s 88ms/step - loss: 0.0505 - val_loss: 1.2438\n",
            "Epoch 109/200\n",
            "1405/1405 [==============================] - 117s 83ms/step - loss: 0.0506 - val_loss: 1.1216\n",
            "Epoch 110/200\n",
            "1405/1405 [==============================] - 117s 84ms/step - loss: 0.0505 - val_loss: 1.1707\n",
            "Epoch 111/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.3690\n",
            "Epoch 112/200\n",
            "1405/1405 [==============================] - 131s 93ms/step - loss: 0.0505 - val_loss: 1.2800\n",
            "Epoch 113/200\n",
            "1405/1405 [==============================] - 129s 92ms/step - loss: 0.0506 - val_loss: 1.3518\n",
            "Epoch 114/200\n",
            "1405/1405 [==============================] - 119s 85ms/step - loss: 0.0505 - val_loss: 1.2472\n",
            "Epoch 115/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0510 - val_loss: 1.1144\n",
            "Epoch 116/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0505 - val_loss: 1.1580\n",
            "Epoch 117/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0505 - val_loss: 1.0797\n",
            "Epoch 118/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0504 - val_loss: 1.1611\n",
            "Epoch 119/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0505 - val_loss: 1.1058\n",
            "Epoch 120/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.1207\n",
            "Epoch 121/200\n",
            "1405/1405 [==============================] - 114s 81ms/step - loss: 0.0505 - val_loss: 1.1412\n",
            "Epoch 122/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0505 - val_loss: 1.0853\n",
            "Epoch 123/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0505 - val_loss: 1.1538\n",
            "Epoch 124/200\n",
            "1405/1405 [==============================] - 117s 83ms/step - loss: 0.0505 - val_loss: 1.1654\n",
            "Epoch 125/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.0189\n",
            "Epoch 126/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0509 - val_loss: 1.1951\n",
            "Epoch 127/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.1824\n",
            "Epoch 128/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0504 - val_loss: 1.1045\n",
            "Epoch 129/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.2328\n",
            "Epoch 130/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0504 - val_loss: 1.1912\n",
            "Epoch 131/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0505 - val_loss: 1.1889\n",
            "Epoch 132/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.2569\n",
            "Epoch 133/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.2503\n",
            "Epoch 134/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0504 - val_loss: 1.1493\n",
            "Epoch 135/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0504 - val_loss: 1.1779\n",
            "Epoch 136/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.0479\n",
            "Epoch 137/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0505 - val_loss: 1.1646\n",
            "Epoch 138/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.1116\n",
            "Epoch 139/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0506 - val_loss: 1.0551\n",
            "Epoch 140/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0505 - val_loss: 1.1342\n",
            "Epoch 141/200\n",
            "1405/1405 [==============================] - 119s 84ms/step - loss: 0.0504 - val_loss: 1.0979\n",
            "Epoch 142/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0505 - val_loss: 1.1873\n",
            "Epoch 143/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0504 - val_loss: 1.2628\n",
            "Epoch 144/200\n",
            "1405/1405 [==============================] - 117s 83ms/step - loss: 0.0505 - val_loss: 1.2890\n",
            "Epoch 145/200\n",
            "1405/1405 [==============================] - 116s 83ms/step - loss: 0.0508 - val_loss: 1.0785\n",
            "Epoch 146/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0504 - val_loss: 1.1517\n",
            "Epoch 147/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0504 - val_loss: 1.2210\n",
            "Epoch 148/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0505 - val_loss: 1.1378\n",
            "Epoch 149/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0505 - val_loss: 1.2883\n",
            "Epoch 150/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0505 - val_loss: 1.3463\n",
            "Epoch 151/200\n",
            "1405/1405 [==============================] - 116s 82ms/step - loss: 0.0504 - val_loss: 1.2149\n",
            "Epoch 152/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0504 - val_loss: 1.1563\n",
            "Epoch 153/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0505 - val_loss: 1.1141\n",
            "Epoch 154/200\n",
            "1405/1405 [==============================] - 115s 82ms/step - loss: 0.0506 - val_loss: 1.1460\n",
            "Epoch 155/200\n",
            "1405/1405 [==============================] - 117s 84ms/step - loss: 0.0506 - val_loss: 1.2153\n",
            "Epoch 156/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0505 - val_loss: 1.2113\n",
            "Epoch 157/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0506 - val_loss: 1.3003\n",
            "Epoch 158/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0506 - val_loss: 1.1916\n",
            "Epoch 159/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0505 - val_loss: 1.1843\n",
            "Epoch 160/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0507 - val_loss: 1.1607\n",
            "Epoch 161/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0506 - val_loss: 1.1621\n",
            "Epoch 162/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0504 - val_loss: 1.1911\n",
            "Epoch 163/200\n",
            "1405/1405 [==============================] - 119s 84ms/step - loss: 0.0505 - val_loss: 1.1654\n",
            "Epoch 164/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0504 - val_loss: 1.1371\n",
            "Epoch 165/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0505 - val_loss: 1.1617\n",
            "Epoch 166/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0505 - val_loss: 1.1154\n",
            "Epoch 167/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0504 - val_loss: 1.1608\n",
            "Epoch 168/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0505 - val_loss: 1.1684\n",
            "Epoch 169/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0506 - val_loss: 1.1670\n",
            "Epoch 170/200\n",
            "1405/1405 [==============================] - 118s 84ms/step - loss: 0.0503 - val_loss: 1.2202\n",
            "Epoch 171/200\n",
            "1405/1405 [==============================] - 123s 88ms/step - loss: 0.0506 - val_loss: 1.2025\n",
            "Epoch 172/200\n",
            "1405/1405 [==============================] - 124s 88ms/step - loss: 0.0505 - val_loss: 1.1715\n",
            "Epoch 173/200\n",
            "1405/1405 [==============================] - 124s 88ms/step - loss: 0.0506 - val_loss: 1.1396\n",
            "Epoch 174/200\n",
            "1405/1405 [==============================] - 4832s 3s/step - loss: 0.0504 - val_loss: 1.1812\n",
            "Epoch 175/200\n",
            "1405/1405 [==============================] - 14674s 10s/step - loss: 0.0506 - val_loss: 1.0743\n",
            "Epoch 176/200\n",
            "1405/1405 [==============================] - 117s 84ms/step - loss: 0.0505 - val_loss: 1.3120\n",
            "Epoch 177/200\n",
            "1405/1405 [==============================] - 41504s 30s/step - loss: 0.0504 - val_loss: 1.1327\n",
            "Epoch 178/200\n",
            "1405/1405 [==============================] - 148s 105ms/step - loss: 0.0505 - val_loss: 1.4445\n",
            "Epoch 179/200\n",
            "1405/1405 [==============================] - 166s 118ms/step - loss: 0.0511 - val_loss: 1.1617\n",
            "Epoch 180/200\n",
            "1405/1405 [==============================] - 135s 96ms/step - loss: 0.0507 - val_loss: 1.1769\n",
            "Epoch 181/200\n",
            "1405/1405 [==============================] - 121s 86ms/step - loss: 0.0509 - val_loss: 1.3446\n",
            "Epoch 182/200\n",
            "1405/1405 [==============================] - 122s 87ms/step - loss: 0.0504 - val_loss: 1.3885\n",
            "Epoch 183/200\n",
            "1405/1405 [==============================] - 119s 84ms/step - loss: 0.0506 - val_loss: 1.2817\n",
            "Epoch 184/200\n",
            "1405/1405 [==============================] - 128s 91ms/step - loss: 0.0505 - val_loss: 1.3435\n",
            "Epoch 185/200\n",
            "1405/1405 [==============================] - 131s 93ms/step - loss: 0.0506 - val_loss: 1.3295\n",
            "Epoch 186/200\n",
            "1405/1405 [==============================] - 141s 101ms/step - loss: 0.0505 - val_loss: 1.2888\n",
            "Epoch 187/200\n",
            "1405/1405 [==============================] - 142s 101ms/step - loss: 0.0505 - val_loss: 1.1846\n",
            "Epoch 188/200\n",
            "1405/1405 [==============================] - 128s 91ms/step - loss: 0.0505 - val_loss: 1.3170\n",
            "Epoch 189/200\n",
            "1405/1405 [==============================] - 126s 90ms/step - loss: 0.0505 - val_loss: 1.1030\n",
            "Epoch 190/200\n",
            "1405/1405 [==============================] - 133s 95ms/step - loss: 0.0506 - val_loss: 1.4330\n",
            "Epoch 191/200\n",
            "1405/1405 [==============================] - 135s 96ms/step - loss: 0.0506 - val_loss: 1.5512\n",
            "Epoch 192/200\n",
            "1405/1405 [==============================] - 129s 92ms/step - loss: 0.0505 - val_loss: 1.2562\n",
            "Epoch 193/200\n",
            "1405/1405 [==============================] - 233s 166ms/step - loss: 0.0504 - val_loss: 1.4566\n",
            "Epoch 194/200\n",
            "1405/1405 [==============================] - 141s 101ms/step - loss: 0.0504 - val_loss: 1.2771\n",
            "Epoch 195/200\n",
            "1405/1405 [==============================] - 159s 113ms/step - loss: 0.0505 - val_loss: 1.3359\n",
            "Epoch 196/200\n",
            "1405/1405 [==============================] - 146s 104ms/step - loss: 0.0506 - val_loss: 1.2736\n",
            "Epoch 197/200\n",
            "1405/1405 [==============================] - 130s 93ms/step - loss: 0.0504 - val_loss: 1.1238\n",
            "Epoch 198/200\n",
            "1405/1405 [==============================] - 124s 88ms/step - loss: 0.0507 - val_loss: 1.3326\n",
            "Epoch 199/200\n",
            "1405/1405 [==============================] - 140s 100ms/step - loss: 0.0505 - val_loss: 1.4622\n",
            "Epoch 200/200\n",
            "1405/1405 [==============================] - 124s 89ms/step - loss: 0.0505 - val_loss: 1.4099\n"
          ]
        }
      ],
      "source": [
        "history=transformer.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=200\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9idy320ZEjq9"
      },
      "outputs": [],
      "source": [
        "index_to_word={x:y for x, y in zip(range(len(english_vectorize_layer1.get_vocabulary())),\n",
        "                                   english_vectorize_layer1.get_vocabulary())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2y3kQ1Gpdl4",
        "outputId": "05f70d9f-2cf0-4391-cb77-b7d9eabad370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '', 1: '[UNK]', 2: 'starttoken', 3: 'endtoken', 4: 'your', 5: 'object', 6: 'ill', 7: 'to', 8: 'you', 9: 'find', 10: 'im', 11: 'assist', 12: 'a', 13: 'of', 14: 'in', 15: 'for', 16: 'do', 17: 'right', 18: 'help', 19: 'locating', 20: 'course', 21: 'my', 22: 'moment', 23: 'thing', 24: 'me', 25: 'locate', 26: 'give', 27: 'best', 28: 'now', 29: 'searching', 30: 'sure', 31: 'i', 32: 'and', 33: 'that', 34: 'have', 35: 'dont', 36: 'information', 37: 'sorry', 38: 'the', 39: 'here', 40: 'with', 41: 'involves', 42: 'can', 43: 'today', 44: 'how', 45: 'is', 46: 'whats', 47: 'like', 48: 'cant', 49: 'good', 50: 'from', 51: 'but', 52: 'moving', 53: 'what', 54: 'on', 55: 'becoming', 56: 'hi', 57: 'are', 58: 'preferences', 59: 'hello', 60: 'often', 61: 'more', 62: 'hey', 63: 'afternoon', 64: 'world', 65: 'it', 66: 'evening', 67: 'morning', 68: 'also', 69: 'this', 70: 'be', 71: 'new', 72: 'left', 73: 'top', 74: 'our', 75: 'life', 76: 'its', 77: 'bottom', 78: 'time', 79: 'many', 80: 'understanding', 81: 'practicing', 82: 'all', 83: 'great', 84: 'staying', 85: 'setting', 86: 'greetings', 87: 'ears', 88: 'too', 89: 'sleep', 90: 'favorite', 91: 'enjoy', 92: 'day', 93: 'skills', 94: 'service', 95: 'fostering', 96: 'better', 97: 'nature', 98: 'agenda', 99: 'support', 100: 'pursuing', 101: 'or', 102: 'natural', 103: 'goals', 104: 'fulfilling', 105: 'embracing', 106: 'effective', 107: 'communication', 108: 'active', 109: 'supporting', 110: 'retirement', 111: 'make', 112: 'maintaining', 113: 'forward', 114: 'finding', 115: 'family', 116: 'away', 117: 'people', 118: 'learning', 119: 'human', 120: 'exploring', 121: 'during', 122: 'creating', 123: 'building', 124: 'as', 125: 'there', 126: 'resilience', 127: 'mind', 128: 'art', 129: 'successful', 130: 'developing', 131: 'connect', 132: 'center', 133: 'by', 134: 'seeking', 135: 'reducing', 136: 'open', 137: 'not', 138: 'may', 139: 'making', 140: 'different', 141: 'creativity', 142: 'work', 143: 'techniques', 144: 'plan', 145: 'managing', 146: 'listening', 147: 'just', 148: 'going', 149: 'conservation', 150: 'brings', 151: 'well', 152: 'unique', 153: 'tonight', 154: 'scientific', 155: 'peaceful', 156: 'offer', 157: 'much', 158: 'market', 159: 'experiences', 160: 'engineering', 161: 'brighten', 162: 'boundaries', 163: 'universe', 164: 'todo', 165: 'space', 166: 'problem', 167: 'passions', 168: 'others', 169: 'everything', 170: 'energy', 171: 'culture', 172: 'clear', 173: 'chat', 174: 'about', 175: 'wonders', 176: 'wonderful', 177: 'travel', 178: 'strategies', 179: 'public', 180: 'prioritizing', 181: 'practices', 182: 'positive', 183: 'music', 184: 'management', 185: 'list', 186: 'happening', 187: 'genres', 188: 'even', 189: 'environment', 190: 'cuisine', 191: 'conserving', 192: 'community', 193: 'challenging', 194: 'animal', 195: 'an', 196: 'traditions', 197: 'sustainable', 198: 'regular', 199: 'questions', 200: 'perspectives', 201: 'mysteries', 202: 'local', 203: 'includes', 204: 'exciting', 205: 'effectively', 206: 'diverse', 207: 'coping', 208: 'contributing', 209: 'change', 210: 'certainly', 211: 'buzz', 212: 'being', 213: 'activities', 214: 'waste', 215: 'using', 216: 'theory', 217: 'strong', 218: 'social', 219: 'shared', 220: 'saving', 221: 'opportunity', 222: 'nights', 223: 'lifelong', 224: 'leading', 225: 'leader', 226: 'job', 227: 'innovation', 228: 'improving', 229: 'financial', 230: 'engaging', 231: 'emotional', 232: 'desserts', 233: 'dark', 234: 'balanced', 235: 'ability', 236: 'yourself', 237: 'worklife', 238: 'trying', 239: 'thinking', 240: 'technological', 241: 'taste', 242: 'stress', 243: 'spending', 244: 'speaker', 245: 'selfcare', 246: 'resources', 247: 'practice', 248: 'persuasive', 249: 'outdoor', 250: 'ones', 251: 'mutual', 252: 'loved', 253: 'know', 254: 'impact', 255: 'ideas', 256: 'friendships', 257: 'forms', 258: 'emotions', 259: 'discoveries', 260: 'did', 261: 'development', 262: 'dessert', 263: 'deep', 264: 'days', 265: 'dance', 266: 'cuisines', 267: 'continue', 268: 'challenge', 269: 'adaptable', 270: 'ways', 271: 'various', 272: 'trust', 273: 'together', 274: 'times', 275: 'team', 276: 'sources', 277: 'solutions', 278: 'socially', 279: 'showcasing', 280: 'showcase', 281: 'selfcompassion', 282: 'sculpture', 283: 'relativity', 284: 'planet', 285: 'philosophical', 286: 'pets', 287: 'pet', 288: 'perfect', 289: 'one', 290: 'needs', 291: 'mindfulness', 292: 'memorable', 293: 'matter', 294: 'joyful', 295: 'joy', 296: 'international', 297: 'inspiration', 298: 'informed', 299: 'influential', 300: 'impressive', 301: 'immersing', 302: 'hobbies', 303: 'hiking', 304: 'harmonious', 305: 'empathetic', 306: 'dogs', 307: 'decisions', 308: 'cosmic', 309: 'concepts', 310: 'comfortable', 311: 'cats', 312: 'budgeting', 313: 'architectural', 314: 'wall', 315: 'vision', 316: 'up', 317: 'transformed', 318: 'their', 319: 'station', 320: 'solving', 321: 'simply', 322: 'science', 323: 'schedule', 324: 'respect', 325: 'relaxation', 326: 'migration', 327: 'message', 328: 'memories', 329: 'marvels', 330: 'lifestyle', 331: 'ingenuity', 332: 'idea', 333: 'iconic', 334: 'healthier', 335: 'flavors', 336: 'finances', 337: 'feats', 338: 'experience', 339: 'exercise', 340: 'destinations', 341: 'daily', 342: 'creative', 343: 'continuous', 344: 'connecting', 345: 'companionship', 346: 'collaboration', 347: 'china', 348: 'changing', 349: 'challenges', 350: 'bring', 351: 'behaviors', 352: 'begins', 353: 'beauty', 354: 'aweinspiring', 355: 'audience', 356: 'align', 357: 'advocating', 358: 'adapt', 359: 'without', 360: 'willingness', 361: 'wildlife', 362: 'wellbeing', 363: 'through', 364: 'tasks', 365: 'scientists', 366: 'routine', 367: 'restful', 368: 'refining', 369: 'read', 370: 'range', 371: 'quality', 372: 'priorities', 373: 'position', 374: 'pie', 375: 'picnics', 376: 'physics', 377: 'physical', 378: 'phenomena', 379: 'personal', 380: 'painting', 381: 'offering', 382: 'nurturing', 383: 'network', 384: 'minimizing', 385: 'love', 386: 'lasting', 387: 'intelligence', 388: 'inspires', 389: 'initiatives', 390: 'happy', 391: 'growth', 392: 'genre', 393: 'future', 394: 'fiction', 395: 'fascinating', 396: 'ethics', 397: 'efficient', 398: 'distractions', 399: 'culinary', 400: 'consistent', 401: 'connected', 402: 'competitive', 403: 'chocolate', 404: 'cheesecake', 405: 'camping', 406: 'business', 407: 'brainstorming', 408: 'book', 409: 'balance', 410: 'at', 411: 'astronomers', 412: 'artificial', 413: 'apple', 414: 'adventures', 415: 'adventure', 416: 'advancements', 417: 'activity', 418: 'writing', 419: 'works', 420: 'wide', 421: 'way', 422: 'us', 423: 'thriving', 424: 'taking', 425: 'takes', 426: 'startup', 427: 'speaking', 428: 'same', 429: 'rock', 430: 'revolutionized', 431: 'resonates', 432: 'research', 433: 'relationships', 434: 'professional', 435: 'productivity', 436: 'prioritization', 437: 'preparation', 438: 'outside', 439: 'other', 440: 'opportunities', 441: 'need', 442: 'movies', 443: 'motion', 444: 'moral', 445: 'mastering', 446: 'located', 447: 'lives', 448: 'language', 449: 'internet', 450: 'innovations', 451: 'friends', 452: 'footprint', 453: 'fantasy', 454: 'failure', 455: 'excelling', 456: 'efforts', 457: 'ecofriendly', 458: 'dreams', 459: 'discovery', 460: 'demonstrate', 461: 'delivery', 462: 'cultures', 463: 'corner', 464: 'communicator', 465: 'carbon', 466: 'captivate', 467: 'books', 468: 'bonds', 469: 'audiences', 470: 'assumptions', 471: 'achieving', 472: 'we', 473: 'values', 474: 'unconventional', 475: 'tiramisu', 476: 'theoretical', 477: 'tech', 478: 'take', 479: 'such', 480: 'structure', 481: 'storytelling', 482: 'start', 483: 'span', 484: 'so', 485: 'smartphones', 486: 'set', 487: 'sense', 488: 'renewable', 489: 'remind', 490: 'recommend', 491: 'recharge', 492: 'quantum', 493: 'purpose', 494: 'processes', 495: 'present', 496: 'possibility', 497: 'policies', 498: 'photography', 499: 'peoples', 500: 'offthebeatenpath', 501: 'off', 502: 'nutrition', 503: 'networking', 504: 'moon', 505: 'monarch', 506: 'mobilizing', 507: 'mental', 508: 'members', 509: 'meaning', 510: 'longterm', 511: 'literature', 512: 'listener', 513: 'landing', 514: 'involve', 515: 'intrigue', 516: 'into', 517: 'incredible', 518: 'hunting', 519: 'healthy', 520: 'has', 521: 'greener', 522: 'grand', 523: 'global', 524: 'giza', 525: 'fully', 526: 'form', 527: 'foods', 528: 'extraterrestrial', 529: 'experimenting', 530: 'environmental', 531: 'enjoying', 532: 'emotionally', 533: 'electric', 534: 'eat', 535: 'diet', 536: 'delicious', 537: 'cultivating', 538: 'cooperative', 539: 'conversations', 540: 'contemplation', 541: 'construction', 542: 'consciousness', 543: 'connections', 544: 'compelling', 545: 'classical', 546: 'cherished', 547: 'canyon', 548: 'cake', 549: 'butterflies', 550: 'birds', 551: 'beloved', 552: 'beautiful', 553: 'authentic', 554: 'array', 555: 'around', 556: 'winwin', 557: 'when', 558: 'weather', 559: 'watch', 560: 'was', 561: 'warm', 562: 'visual', 563: 'vehicles', 564: 'value', 565: 'validating', 566: 'universes', 567: 'tunnel', 568: 'trolley', 569: 'traveling', 570: 'thorough', 571: 'than', 572: 'technologies', 573: 'taj', 574: 'swimming', 575: 'sunny', 576: 'styles', 577: 'strengthen', 578: 'starts', 579: 'spring', 580: 'sports', 581: 'spontaneity', 582: 'solver', 583: 'solar', 584: 'showing', 585: 'shaping', 586: 'see', 587: 'romance', 588: 'rich', 589: 'reshaped', 590: 'requires', 591: 'reflection', 592: 'reasoning', 593: 'reality', 594: 'rabbits', 595: 'pyramid', 596: 'push', 597: 'promote', 598: 'popular', 599: 'playing', 600: 'places', 601: 'persuasion', 602: 'path', 603: 'parrots', 604: 'overcoming', 605: 'out', 606: 'organizations', 607: 'online', 608: 'nurtured', 609: 'neutron', 610: 'negotiator', 611: 'mystery', 612: 'motivated', 613: 'most', 614: 'media', 615: 'marketing', 616: 'mahal', 617: 'lived', 618: 'landmarks', 619: 'kingdom', 620: 'kind', 621: 'jazz', 622: 'invite', 623: 'intricate', 624: 'interview', 625: 'interests', 626: 'inclusivity', 627: 'ice', 628: 'honing', 629: 'historical', 630: 'harmony', 631: 'habitat', 632: 'groundbreaking', 633: 'giving', 634: 'genome', 635: 'gene', 636: 'fruit', 637: 'friend', 638: 'formation', 639: 'fireplace', 640: 'explore', 641: 'examples', 642: 'example', 643: 'evolution', 644: 'ethical', 645: 'environmentally', 646: 'entrepreneurial', 647: 'encompasses', 648: 'empowering', 649: 'empathy', 650: 'egypt', 651: 'editing', 652: 'each', 653: 'drawing', 654: 'drama', 655: 'disruptive', 656: 'dilemmas', 657: 'dense', 658: 'demonstrating', 659: 'currency', 660: 'cultural', 661: 'cream', 662: 'cozy', 663: 'cosmos', 664: 'conscious', 665: 'concept', 666: 'complex', 667: 'comes', 668: 'comedy', 669: 'collaborative', 670: 'closer', 671: 'climbing', 672: 'cleopatra', 673: 'circumstances', 674: 'cherishing', 675: 'channel', 676: 'capital', 677: 'built', 678: 'breakthroughs', 679: 'borealis', 680: 'bees', 681: 'been', 682: 'beaten', 683: 'back', 684: 'aurora', 685: 'asking', 686: 'ancient', 687: 'action', 688: 'achievement', 689: '6', 690: 'youre', 691: 'would', 692: 'worldwide', 693: 'workplace', 694: 'wonder', 695: 'wolves', 696: 'will', 697: 'widely', 698: 'weigh', 699: 'waves', 700: 'want', 701: 'victoria', 702: 'venture', 703: 'vastness', 704: 'unwind', 705: 'unsolved', 706: 'universal', 707: 'understand', 708: 'treat', 709: 'transformative', 710: 'tower', 711: 'tough', 712: 'tons', 713: 'thoughtprovoking', 714: 'theories', 715: 'them', 716: 'thank', 717: 'testaments', 718: 'testament', 719: 'tapestry', 720: 'tailoring', 721: 'symbols', 722: 'sustainability', 723: 'summer', 724: 'streamline', 725: 'stepping', 726: 'starting', 727: 'star', 728: 'square', 729: 'spectacles', 730: 'species', 731: 'society', 732: 'snowy', 733: 'significance', 734: 'showers', 735: 'seek', 736: 'seasons', 737: 'season', 738: 'sculptures', 739: 'sanctuaries', 740: 'root', 741: 'rituals', 742: 'rise', 743: 'revolutionizing', 744: 'restoration', 745: 'respectfully', 746: 'resolving', 747: 'relevant', 748: 'relaxing', 749: 'relax', 750: 'relationship', 751: 'regularly', 752: 'reading', 753: 'pyramids', 754: 'prowess', 755: 'provide', 756: 'profound', 757: 'problemsolving', 758: 'problems', 759: 'power', 760: 'possibilities', 761: 'planning', 762: 'plankton', 763: 'pharaoh', 764: 'person', 765: 'patient', 766: 'parties', 767: 'parthenon', 768: 'park', 769: 'paris', 770: 'parallel', 771: 'panama', 772: 'paintings', 773: 'owners', 774: 'overall', 775: 'organized', 776: 'organization', 777: 'only', 778: 'offers', 779: 'northern', 780: 'never', 781: 'needed', 782: 'musical', 783: 'multiverse', 784: 'movie', 785: 'mockingbird', 786: 'mindset', 787: 'mimicry', 788: 'mild', 789: 'migrations', 790: 'meteor', 791: 'meditation', 792: 'medicine', 793: 'mechanics', 794: 'meaningful', 795: 'marriages', 796: 'mapping', 797: 'lovely', 798: 'longlasting', 799: 'long', 800: 'locals', 801: 'live', 802: 'lights', 803: 'light', 804: 'lessons', 805: 'leisure', 806: 'latest', 807: 'last', 808: 'languages', 809: 'knowledge', 810: 'kill', 811: 'khalifa', 812: 'kayaking', 813: 'ive', 814: 'itself', 815: 'instruments', 816: 'inspiring', 817: 'industries', 818: 'incredibly', 819: 'increasing', 820: 'incorporating', 821: 'including', 822: 'hypothesis', 823: 'holes', 824: 'hive', 825: 'history', 826: 'hiphop', 827: 'higgs', 828: 'hidden', 829: 'heres', 830: 'had', 831: 'green', 832: 'gravitational', 833: 'geysers', 834: 'generate', 835: 'gems', 836: 'fundamental', 837: 'free', 838: 'france', 839: 'flowers', 840: 'fitness', 841: 'feelings', 842: 'feedback', 843: 'falls', 844: 'exploration', 845: 'existence', 846: 'exhilarating', 847: 'execution', 848: 'everyday', 849: 'events', 850: 'enthusiasm', 851: 'entanglement', 852: 'enjoyable', 853: 'empathizing', 854: 'ecosystems', 855: 'eclipses', 856: 'echolocation', 857: 'earths', 858: 'earth', 859: 'dynamics', 860: 'diversity', 861: 'dishes', 862: 'disappearance', 863: 'digital', 864: 'destination', 865: 'decisionmaking', 866: 'dances', 867: 'curiosity', 868: 'cup', 869: 'critical', 870: 'craftsmanship', 871: 'courtship', 872: 'could', 873: 'cooking', 874: 'conventional', 875: 'considered', 876: 'conflicts', 877: 'confident', 878: 'compromise', 879: 'composition', 880: 'communicate', 881: 'common', 882: 'colosseum', 883: 'code', 884: 'chinese', 885: 'canal', 886: 'canada', 887: 'calming', 888: 'burj', 889: 'build', 890: 'brighter', 891: 'breathtaking', 892: 'breaks', 893: 'box', 894: 'both', 895: 'boson', 896: 'bond', 897: 'blooming', 898: 'black', 899: 'bioluminescent', 900: 'billion', 901: 'beyond', 902: 'between', 903: 'before', 904: 'bedtime', 905: 'because', 906: 'based', 907: 'backpacking', 908: 'arguments', 909: 'anxiety', 910: 'antibiotics', 911: 'answers', 912: 'another', 913: 'among', 914: 'ambiguity', 915: 'allowing', 916: 'air', 917: 'africa', 918: 'addressing', 919: 'adaptations', 920: 'acing', 921: 'achievements', 922: 'accomplish', 923: '', 924: 'en', 925: 'zone', 926: 'yours', 927: 'yen', 928: 'years', 929: 'year', 930: 'writer', 931: 'write', 932: 'wounds', 933: 'worlds', 934: 'workouts', 935: 'workflows', 936: 'workflow', 937: 'word', 938: 'woods', 939: 'wont', 940: 'winter', 941: 'wildebeests', 942: 'wildebeest', 943: 'why', 944: 'whitewater', 945: 'which', 946: 'whales', 947: 'welcome', 948: 'watts', 949: 'war', 950: 'walks', 951: 'walk', 952: 'waiting', 953: 'volunteering', 954: 'volunteer', 955: 'volts', 956: 'volcanic', 957: 'visuals', 958: 'visible', 959: 'vincis', 960: 'vincent', 961: 'vast', 962: 'varying', 963: 'variety', 964: 'varies', 965: 'van', 966: 'valuable', 967: 'vacuum', 968: 'used', 969: 'use', 970: 'ups', 971: 'united', 972: 'unconditional', 973: 'uncertainty', 974: 'type', 975: 'twice', 976: 'tutorials', 977: 'try', 978: 'truly', 979: 'triggers', 980: 'tried', 981: 'triangle', 982: 'tranquility', 983: 'trains', 984: 'tools', 985: 'took', 986: 'tones', 987: 'tone', 988: 'throughout', 989: 'thrive', 990: 'thousand', 991: 'those', 992: 'thirst', 993: 'think', 994: 'theyre', 995: 'they', 996: 'theres', 997: 'thats', 998: 'text', 999: 'test', 1000: 'tennis', 1001: 'telescopes', 1002: 'teaspoonful', 1003: 'teaspoon', 1004: 'teamwork', 1005: 'tea', 1006: 'tarts', 1007: 'tart', 1008: 'tackle', 1009: 'system', 1010: 'symbolize', 1011: 'swarms', 1012: 'suspension', 1013: 'survive', 1014: 'superposition', 1015: 'sun', 1016: 'successes', 1017: 'success', 1018: 'subjects', 1019: 'subjective', 1020: 'stunning', 1021: 'stun', 1022: 'studying', 1023: 'structuring', 1024: 'stroll', 1025: 'strengths', 1026: 'street', 1027: 'streamlining', 1028: 'storyteller', 1029: 'storied', 1030: 'stones', 1031: 'steve', 1032: 'steps', 1033: 'stay', 1034: 'status', 1035: 'statue', 1036: 'static', 1037: 'startups', 1038: 'stars', 1039: 'starry', 1040: 'stargazers', 1041: 'spot', 1042: 'sport', 1043: 'spirit', 1044: 'spent', 1045: 'speeches', 1046: 'specific', 1047: 'special', 1048: 'spark', 1049: 'spacetime', 1050: 'sound', 1051: 'something', 1052: 'some', 1053: 'solve', 1054: 'solid', 1055: 'soft', 1056: 'soccer', 1057: 'snowman', 1058: 'snowboarding', 1059: 'snowball', 1060: 'smartphone', 1061: 'smaller', 1062: 'skyscrapers', 1063: 'skydiving', 1064: 'skiing', 1065: 'situations', 1066: 'silent', 1067: 'shows', 1068: 'shopping', 1069: 'shocks', 1070: 'shawshank', 1071: 'sharing', 1072: 'shanghai', 1073: 'settings', 1074: 'setbacks', 1075: 'selftalk', 1076: 'selfreflection', 1077: 'selfesteem', 1078: 'selfacceptance', 1079: 'self', 1080: 'selection', 1081: 'seen', 1082: 'secret', 1083: 'search', 1084: 'seamless', 1085: 'screen', 1086: 'savoring', 1087: 'santorini', 1088: 'sandwiches', 1089: 'rome', 1090: 'romantic', 1091: 'roman', 1092: 'role', 1093: 'roger', 1094: 'roanoke', 1095: 'risks', 1096: 'ripper', 1097: 'richness', 1098: 'revolutionary', 1099: 'revolution', 1100: 'resume', 1101: 'restaurants', 1102: 'responsible', 1103: 'respective', 1104: 'respectful', 1105: 'resolution', 1106: 'reshaping', 1107: 'replacement', 1108: 'repetitive', 1109: 'renaissance', 1110: 'remarkable', 1111: 'rejuvenating', 1112: 'reinhard', 1113: 'regions', 1114: 'refreshing', 1115: 'reframing', 1116: 'refine', 1117: 'reef', 1118: 'redemption', 1119: 'recreational', 1120: 'recognizing', 1121: 'recognized', 1122: 'recipes', 1123: 'realistic', 1124: 'rapport', 1125: 'raising', 1126: 'rainy', 1127: 'rainforest', 1128: 'rafting', 1129: 'qu', 1130: 'quo', 1131: 'quiet', 1132: 'questioning', 1133: 'question', 1134: 'qualities', 1135: 'python', 1136: 'pushing', 1137: 'pull', 1138: 'puedo', 1139: 'protection', 1140: 'proposition', 1141: 'proposed', 1142: 'project', 1143: 'programming', 1144: 'programmed', 1145: 'program', 1146: 'products', 1147: 'productive', 1148: 'product', 1149: 'procrastination', 1150: 'process', 1151: 'prize', 1152: 'principles', 1153: 'primary', 1154: 'pride', 1155: 'prey', 1156: 'prevent', 1157: 'pressing', 1158: 'preparing', 1159: 'prejudice', 1160: 'predators', 1161: 'powerful', 1162: 'pound', 1163: 'possible', 1164: 'possess', 1165: 'pop', 1166: 'pleasure', 1167: 'play', 1168: 'plants', 1169: 'planets', 1170: 'pies', 1171: 'pieces', 1172: 'picking', 1173: 'picchu', 1174: 'physically', 1175: 'philosophy', 1176: 'peru', 1177: 'persistence', 1178: 'perseverance', 1179: 'perplex', 1180: 'penrose', 1181: 'penguins', 1182: 'peace', 1183: 'pastrami', 1184: 'passion', 1185: 'participating', 1186: 'part', 1187: 'parks', 1188: 'own', 1189: 'overcome', 1190: 'over', 1191: 'outdoors', 1192: 'organ', 1193: 'orcas', 1194: 'optimizing', 1195: 'openminded', 1196: 'opened', 1197: 'once', 1198: 'octopuses', 1199: 'ocean', 1200: 'nyc', 1201: 'nutritious', 1202: 'nobel', 1203: 'no', 1204: 'night', 1205: 'nice', 1206: 'negotiation', 1207: 'neck', 1208: 'natures', 1209: 'national', 1210: 'narrative', 1211: 'name', 1212: 'mutually', 1213: 'multiple', 1214: 'mousse', 1215: 'morality', 1216: 'mood', 1217: 'money', 1218: 'mona', 1219: 'modern', 1220: 'mobydick', 1221: 'minute', 1222: 'mine', 1223: 'mindexpanding', 1224: 'mindboggling', 1225: 'mindbending', 1226: 'miles', 1227: 'mesmerizing', 1228: 'mediums', 1229: 'medical', 1230: 'meals', 1231: 'masterpieces', 1232: 'marvel', 1233: 'marked', 1234: 'mark', 1235: 'manmade', 1236: 'manager', 1237: 'machu', 1238: 'lows', 1239: 'loving', 1240: 'literary', 1241: 'lists', 1242: 'listen', 1243: 'lisa', 1244: 'lime', 1245: 'lifes', 1246: 'liberty', 1247: 'leveraging', 1248: 'lesson', 1249: 'leonardo', 1250: 'leisurely', 1251: 'learned', 1252: 'lava', 1253: 'launching', 1254: 'laughter', 1255: 'laterally', 1256: 'large', 1257: 'known', 1258: 'kindness', 1259: 'killer', 1260: 'key', 1261: 'katzs', 1262: 'jumping', 1263: 'jump', 1264: 'judgment', 1265: 'joys', 1266: 'journey', 1267: 'jobs', 1268: 'japanese', 1269: 'japan', 1270: 'jack', 1271: 'iterate', 1272: 'italian', 1273: 'issues', 1274: 'issue', 1275: 'investing', 1276: 'inventions', 1277: 'introspection', 1278: 'intriguing', 1279: 'intrigues', 1280: 'intimacy', 1281: 'interviews', 1282: 'interactions', 1283: 'intelligent', 1284: 'integrate', 1285: 'inspire', 1286: 'innovative', 1287: 'infection', 1288: 'industrial', 1289: 'indelible', 1290: 'include', 1291: 'improve', 1292: 'impacts', 1293: 'impactful', 1294: 'immersion', 1295: 'immediate', 1296: 'imaginations', 1297: 'images', 1298: 'if', 1299: 'identity', 1300: 'identifying', 1301: 'identify', 1302: 'id', 1303: 'icecold', 1304: 'humor', 1305: 'humans', 1306: 'hubble', 1307: 'hoy', 1308: 'hot', 1309: 'honey', 1310: 'homes', 1311: 'hitchhikers', 1312: 'historic', 1313: 'highspeed', 1314: 'highs', 1315: 'highlight', 1316: 'helping', 1317: 'helpful', 1318: 'heard', 1319: 'health', 1320: 'havent', 1321: 'hammock', 1322: 'hadron', 1323: 'habits', 1324: 'habitable', 1325: 'habit', 1326: 'guitar', 1327: 'guide', 1328: 'grow', 1329: 'ground', 1330: 'greece', 1331: 'gravity', 1332: 'goghs', 1333: 'ghez', 1334: 'getting', 1335: 'genzel', 1336: 'generates', 1337: 'gelato', 1338: 'gardening', 1339: 'galaxy', 1340: 'galaxies', 1341: 'fulfillment', 1342: 'fueled', 1343: 'friendly', 1344: 'freedom', 1345: 'founded', 1346: 'forests', 1347: 'fondue', 1348: 'fondness', 1349: 'focused', 1350: 'focus', 1351: 'flexible', 1352: 'fit', 1353: 'first', 1354: 'financially', 1355: 'fight', 1356: 'field', 1357: 'feet', 1358: 'feel', 1359: 'fear', 1360: 'facilitating', 1361: 'expression', 1362: 'experimentation', 1363: 'experiment', 1364: 'expectations', 1365: 'expansion', 1366: 'expanding', 1367: 'expanded', 1368: 'exoplanets', 1369: 'existentialism', 1370: 'evolved', 1371: 'evidence', 1372: 'event', 1373: 'establishing', 1374: 'essential', 1375: 'escape', 1376: 'eruptions', 1377: 'eras', 1378: 'entrepreneurs', 1379: 'ensure', 1380: 'enhancing', 1381: 'english', 1382: 'endeavors', 1383: 'encouraging', 1384: 'encompass', 1385: 'employers', 1386: 'empathize', 1387: 'embrace', 1388: 'else', 1389: 'electronic', 1390: 'electrical', 1391: 'einstein', 1392: 'eiffel', 1393: 'egyptians', 1394: 'eerily', 1395: 'eel', 1396: 'ecommerce', 1397: 'early', 1398: 'earhart', 1399: 'ear', 1400: 'dynamic', 1401: 'due', 1402: 'drinks', 1403: 'dream', 1404: 'downs', 1405: 'dollar', 1406: 'doing', 1407: 'dnas', 1408: 'dna', 1409: 'distant', 1410: 'displays', 1411: 'discussion', 1412: 'disconnecting', 1413: 'difficult', 1414: 'determination', 1415: 'deter', 1416: 'detection', 1417: 'destruction', 1418: 'design', 1419: 'depth', 1420: 'delve', 1421: 'delivering', 1422: 'delightful', 1423: 'delicatessen', 1424: 'dedication', 1425: 'decoding', 1426: 'decluttering', 1427: 'debt', 1428: 'debate', 1429: 'dealing', 1430: 'deadlines', 1431: 'data', 1432: 'da', 1433: 'cycling', 1434: 'customer', 1435: 'crme', 1436: 'crucial', 1437: 'crispr', 1438: 'crisp', 1439: 'create', 1440: 'crafting', 1441: 'cozying', 1442: 'cover', 1443: 'countless', 1444: 'convey', 1445: 'controlling', 1446: 'continuously', 1447: 'content', 1448: 'contemporary', 1449: 'connectivity', 1450: 'conflict', 1451: 'confidence', 1452: 'concentration', 1453: 'computer', 1454: 'complexity', 1455: 'completely', 1456: 'compassion', 1457: 'companions', 1458: 'communicating', 1459: 'comfort', 1460: 'come', 1461: 'colorful', 1462: 'colony', 1463: 'collider', 1464: 'colleagues', 1465: 'collaborations', 1466: 'collaborating', 1467: 'cocoa', 1468: 'climate', 1469: 'cleaners', 1470: 'clean', 1471: 'classes', 1472: 'civilizations', 1473: 'city', 1474: 'chore', 1475: 'choices', 1476: 'choice', 1477: 'chitty', 1478: 'characterized', 1479: 'century', 1480: 'centuries', 1481: 'celestial', 1482: 'celebrating', 1483: 'celebrated', 1484: 'carry', 1485: 'carnival', 1486: 'career', 1487: 'captivating', 1488: 'canberra', 1489: 'canadian', 1490: 'camouflage', 1491: 'calm', 1492: 'calendars', 1493: 'calculated', 1494: 'businesses', 1495: 'bungee', 1496: 'budget', 1497: 'brle', 1498: 'british', 1499: 'bridges', 1500: 'breathtakingly', 1501: 'breathing', 1502: 'breaking', 1503: 'breakfast', 1504: 'break', 1505: 'brazil', 1506: 'brain', 1507: 'boosting', 1508: 'body', 1509: 'biking', 1510: 'biggest', 1511: 'bermuda', 1512: 'beneficial', 1513: 'beliefs', 1514: 'bee', 1515: 'bed', 1516: 'become', 1517: 'beaches', 1518: 'bc', 1519: 'bats', 1520: 'basking', 1521: 'basketball', 1522: 'barrier', 1523: 'banff', 1524: 'bad', 1525: 'ayudarte', 1526: 'awareness', 1527: 'awarded', 1528: 'awake', 1529: 'avenues', 1530: 'autumn', 1531: 'autonomous', 1532: 'automate', 1533: 'australia', 1534: 'attention', 1535: 'atoms', 1536: 'astrophysicists', 1537: 'aspirations', 1538: 'artistic', 1539: 'artist', 1540: 'articulate', 1541: 'apps', 1542: 'approach', 1543: 'appreciate', 1544: 'application', 1545: 'anywhere', 1546: 'any', 1547: 'ants', 1548: 'antibiotic', 1549: 'answering', 1550: 'anothers', 1551: 'annual', 1552: 'animals', 1553: 'angles', 1554: 'andrea', 1555: 'amelia', 1556: 'amazon', 1557: 'always', 1558: 'albert', 1559: 'aids', 1560: 'agile', 1561: 'age', 1562: 'afraid', 1563: 'advice', 1564: 'adored', 1565: 'adopting', 1566: 'actively', 1567: 'acknowledging', 1568: 'achievable', 1569: 'access', 1570: '753', 1571: '600', 1572: '5', 1573: '25', 1574: '21st', 1575: '2020', 1576: '20', 1577: '1969', 1578: '144', 1579: '13000', 1580: '12'}\n"
          ]
        }
      ],
      "source": [
        "print(index_to_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rrop6PU0pdfs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmbWAEPXxY6t",
        "outputId": "f50b0dd7-c591-4d2a-defc-0d6f98bac436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "for i in index_to_word:\n",
        "  if index_to_word[i] == 'endtoken':\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ABhiX3FED2ww"
      },
      "outputs": [],
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken'\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "    tokenized_shifted_target=english_vectorize_layer1([shifted_target])\n",
        "    output=transformer.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
        "\n",
        "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    current_word=index_to_word[french_word_index]\n",
        "    if current_word=='endtoken':\n",
        "      break\n",
        "    shifted_target+=' '+current_word\n",
        "  return shifted_target[11:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NyEt-7gjSB0A"
      },
      "outputs": [],
      "source": [
        "# Assuming 'transformer' is your trained TensorFlow model\n",
        "transformer.save_weights('transformer_weights200.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UFwQF8HfSmhD",
        "outputId": "4061684c-8c7f-4d65-cffb-57d7ddf9cb0b"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4b6ee2f7-3a60-48ff-b38f-f5be040d3915\", \"transformer_weights200.h5\", 100629904)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('transformer_weights200.h5')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
